{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "트위터 감정 분석_pytorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dqqbt0nSWSj"
      },
      "source": [
        "#### **데이터 다운로드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEqxCEtRSsFH",
        "outputId": "c4f062db-9361-4df4-b0cf-2799988bab19"
      },
      "source": [
        "# valid\n",
        "!gdown --id 1EBXe8-U5OnDMNbgMRcIDygJzdTKOtEA0\n",
        "\n",
        "# train\n",
        "!gdown --id 1rLFoEejWhc_S2bTEHy7CoDc5jBTpbIBe\n",
        "\n",
        "# test\n",
        "!gdown --id 1ugaRfNbetYH2dxrS8cB5KR07s1kCBPG1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EBXe8-U5OnDMNbgMRcIDygJzdTKOtEA0\n",
            "To: /content/valid.csv\n",
            "100% 31.5k/31.5k [00:00<00:00, 4.68MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rLFoEejWhc_S2bTEHy7CoDc5jBTpbIBe\n",
            "To: /content/train.csv\n",
            "100% 124k/124k [00:00<00:00, 4.01MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ugaRfNbetYH2dxrS8cB5KR07s1kCBPG1\n",
            "To: /content/test.csv\n",
            "100% 168k/168k [00:00<00:00, 5.33MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q4yJaRGSbhN"
      },
      "source": [
        "#### **데이터 형태 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q7W_uVNTJSB"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tNMk6YPNTNa5",
        "outputId": "9cc52cdb-11e4-4347-a290-4308c22d0d5a"
      },
      "source": [
        "train = pd.read_csv('train.csv', header = None)\n",
        "\n",
        "train[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>critic survey ashford hospit prime ahp amp kim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>analyst adopt bullish outlook robert half inte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zack rank strong buy semiconductor stock mlnx ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>setup like watch wed roku iq sfix shop spot ua...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>invesco ivz price target lower credit suiss group</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  critic survey ashford hospit prime ahp amp kim...  0\n",
              "1  analyst adopt bullish outlook robert half inte...  1\n",
              "2  zack rank strong buy semiconductor stock mlnx ...  2\n",
              "3  setup like watch wed roku iq sfix shop spot ua...  2\n",
              "4  invesco ivz price target lower credit suiss group  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNmZjDkiTTay",
        "outputId": "48db1415-cca7-407e-fd10-14a83ae4e1d4"
      },
      "source": [
        "!pip install torchtext==0.8.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 16.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed torchtext-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZz8TRJhSeho"
      },
      "source": [
        "#### **모듈 임포트**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjrzJqIlUAs8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim \n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import os\n",
        "import nltk"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWE4nMP-Upqn",
        "outputId": "01af9c55-1616-4ef1-e99b-ab6bdb48a1e1"
      },
      "source": [
        "# nltk tokenizer 사용\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV1TCyE5u_tB"
      },
      "source": [
        "# 데이터 output root 설정 및 gpu설정\n",
        "output_file_path = './model/'\n",
        "os.makedirs(output_file_path, exist_ok= True)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# random seed 고정\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDaXRAJyupW"
      },
      "source": [
        "#### **필드 정의**\n",
        "필드를 통해 앞으로 어떤 전처리를 할 것인지 정의 <br>\n",
        "label과 text는 각각 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-xMugKCwweE",
        "outputId": "57ac1b7c-e438-4109-89f0-d796005d4059"
      },
      "source": [
        "# 텍스트 데이터 필드 정의\n",
        "text_field = Field(tokenize=word_tokenize, lower=True, include_lengths=True, batch_first=True)\n",
        "# 라벨 데이터 필드 정의\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long)\n",
        "\n",
        "fields = [('text', text_field), ('label', label_field)]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoxaoSVgSuzp"
      },
      "source": [
        "#### **데이터 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrkcvjtay-lz",
        "outputId": "81fdb7d4-6527-489f-b668-3ab0d6dbc61a"
      },
      "source": [
        "# train, valid 데이터 불러오기\n",
        "train, valid = TabularDataset.splits(path='./', train = 'train.csv', validation='valid.csv',\n",
        "                                    format='csv',fields = fields, skip_header = True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vs8HRWf0exO",
        "outputId": "f4068764-c773-4c50-8253-ec016cc5963b"
      },
      "source": [
        "train.fields.items()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('text', <torchtext.data.field.Field object at 0x7ff8ea465250>), ('label', <torchtext.data.field.Field object at 0x7ff8ea4652d0>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HIpaVUhS0dx"
      },
      "source": [
        "#### **데이터 로더로 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1xSgXIc4IWp",
        "outputId": "10fc277b-4601-4a6c-e96f-705071a6fd9e"
      },
      "source": [
        "# train, valid 각각 iterater 데이터 로더로 만들기\n",
        "# train\n",
        "train_loader = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.text),\n",
        "                              device = device, sort = True, sort_within_batch = True)\n",
        "\n",
        "# valid\n",
        "valid_loader = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.text),\n",
        "                              device = device, sort = True, sort_within_batch = True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKg7RIy95cpu"
      },
      "source": [
        "text_field.build_vocab(train, min_freq = 5)\n",
        "vocab_size = len(text_field.vocab) # 1016개"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBqHEwN5jJU",
        "outputId": "95e2e8c1-c9ad-4ca0-e95d-23f99ea00eb3"
      },
      "source": [
        "next(iter(train_loader))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 32]\n",
              "\t[.text]:('[torch.cuda.LongTensor of size 32x5 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
              "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg9qkXFx6Dpk",
        "outputId": "7528956b-510f-4c60-dc61-ecce6eaf2fd6"
      },
      "source": [
        "print(len(train))\n",
        "print(train[0].text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999\n",
            "['analyst', 'adopt', 'bullish', 'outlook', 'robert', 'half', 'intern', 'inc', 'rhi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BNuneKCS7vj"
      },
      "source": [
        "#### **LSTM Classifier 클래스 작성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk-h4biS9kw6"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "  # pytorch로 모델 정의할 때 반드시 nn.Module을 상속받은 후 진행\n",
        "  def __init__(self, vocab_size, dimension = 128):\n",
        "    # 클래스의 첫 시작인 함수, 필요한 여러 변수 선언\n",
        "\n",
        "    super(LSTMClassifier, self).__init__() # 필수 코드 ! \n",
        "\n",
        "    # LSTM에 필요한 변수 선언\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, 300)\n",
        "    self.dimension = dimension\n",
        "    self.lstm = nn.LSTM(input_size=300, hidden_size=dimension, num_layers=1, batch_first = True, bidirectional=True)\n",
        "    self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "    self.fc = nn.Linear(2*dimension, 3) # 클래스가 3개라 3으로 끝나야 함 \n",
        "\n",
        "  def forward(self, text, text_len):\n",
        "    # 모델의 forward를 수행하는 함수\n",
        "    # text, text_len을 변수로 받아 신경망 모델을 forward 방향으로 탈 때 출력을 반환\n",
        "    # 단어 -> encoder -> embedding -> 양방향RNN (LSTM) -> dense -> dense 구조\n",
        "\n",
        "    text_embedding = self.embedding(text) # embedding\n",
        "\n",
        "    # text마다 길이가 다르기 때문에 padding으로 채워주기\n",
        "    packed_input = pack_padded_sequence(text_embedding, text_len.cpu(), batch_first=True, enforce_sorted=False) \n",
        "    packed_output, _ = self.lstm(packed_input)\n",
        "    output, _ = pad_packed_sequence(packed_output, batch_first=True) \n",
        "\n",
        "    out_forward = output[range(len(output)), text_len - 1, :self.dimension] # 잘 모르겠는데,,?\n",
        "    out_reverse = output[:, 0, self.dimension: ] # 무슨 의미일까,,\n",
        "    out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
        "    text_fea = self.drop(out_reduced)\n",
        "\n",
        "    text_out = self.fc(text_fea)\n",
        "    return text_out\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulErZbibTGtC"
      },
      "source": [
        "#### **Train** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvh7cqfLDIjb"
      },
      "source": [
        "# train 함수\n",
        "\n",
        "def train(model, device, optimizer, train_loader, valid_loader, output_file_path, num_epochs = 5):\n",
        "  # 학습에 필요한 변수 선언\n",
        "\n",
        "  running_loss = 0.0\n",
        "  global_step = 0\n",
        "  global_step_list = []\n",
        "  train_loss_list = []\n",
        "  valid_loss_list = []\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  best_valid_loss = float('Inf')\n",
        "  eval_every = 10 # 무슨 용도지\n",
        "\n",
        "  # 모델에게 학습이 진행됨을 알려줌\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for ((text, text_len), labels), _ in train_loader:\n",
        "      # Gpu로 사용할 수 있게 데이터 변환\n",
        "      text = text.to(device)\n",
        "      text_len = text_len.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # model안에서 정의한 forward 진행\n",
        "      output = model(text, text_len)\n",
        "\n",
        "      # forward값과 실제의 차이를 loss로 받음\n",
        "      loss = loss_fn(output, labels)\n",
        "\n",
        "      # optimizer 수행\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      global_step +=1\n",
        "\n",
        "      if global_step % eval_every == 0:\n",
        "        # 10번에 한번 validation을 이용하여 성능 검증\n",
        "        average_train_loss, average_valid_loss = evaluate(model, device, valid_loader, loss_fn,\n",
        "                                                          running_loss, eval_every)\n",
        "        \n",
        "        # 검증이 끝난 뒤 모델에게 학습을 준비 시킴\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # 결과 출력\n",
        "        # print('text :{}\\nlabel :{}\\n'.format(text, labels))\n",
        "        print('Epoch {}, Step {}, train_loss : {:.4f}, valid_loss :{:.4f}'.format(epoch + 1, global_step, average_train_loss, average_valid_loss))\n",
        "\n",
        "        # 결과 저장\n",
        "        train_loss_list.append(average_train_loss)\n",
        "        valid_loss_list.append(average_valid_loss)\n",
        "        global_step_list.append(global_step) # 이건 왜 저장하지\n",
        "\n",
        "\n",
        "        # 기존보다 상태가 좋으면 저장\n",
        "        if best_valid_loss > average_valid_loss:\n",
        "          best_valid_loss = average_valid_loss\n",
        "          save_checkpoint(output_file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
        "          save_metrics(output_file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_step_list)\n",
        "      \n",
        "  save_metrics(output_file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_step_list)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MLU7j0tTR3s"
      },
      "source": [
        "#### **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z0yt37TG3K1"
      },
      "source": [
        "# train 안에서 사용할 evaluation 함수 (검증 함수)\n",
        "def evaluate(model, device, valid_loader, loss_fn, running_loss, eval_every):\n",
        "\n",
        "  # 모델한테 평가 중이라고 알림\n",
        "  model.eval()\n",
        "  valid_running_loss = 0.0\n",
        "\n",
        "  # 학습이 아니기에 최적화를 하지 않는다는 환경을 설정 \n",
        "  with torch.no_grad():\n",
        "    for ((text, text_len), labels), _ in valid_loader:\n",
        "      # GPU 태우기\n",
        "      text = text.to(device)\n",
        "      text_len = text_len.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      output = model(text, text_len)\n",
        "\n",
        "      loss = loss_fn(output, labels)\n",
        "      valid_running_loss += loss.item()\n",
        "\n",
        "  average_train_loss = running_loss / eval_every\n",
        "  average_valid_loss = valid_running_loss / eval_every\n",
        "\n",
        "  return average_train_loss, average_valid_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb5M4otmTZB7"
      },
      "source": [
        "#### **모델 저장을 위한 함수 정의**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GdheLVqL897"
      },
      "source": [
        "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(load_path, model, optimizer, device):\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "\n",
        "def load_metrics(load_path, device):\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMBhHdLGZDa0"
      },
      "source": [
        "#### **학습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpLvUrE6tzW"
      },
      "source": [
        "# LSTM 클래스의 인스턴스 생성\n",
        "model = LSTMClassifier(vocab_size).to(device)\n",
        "\n",
        "# optimizer 생성\n",
        "optim = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDHuVW-xL0Cd",
        "outputId": "28088581-fa89-42f9-ccd0-8a2ec6e42fd8"
      },
      "source": [
        "train(model, device, optim, train_loader, valid_loader, output_file_path, 4)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 10, train_loss : 0.8570, valid_loss :1.6047\n",
            "Epoch 1, Step 20, train_loss : 0.7993, valid_loss :1.5476\n",
            "Epoch 1, Step 30, train_loss : 0.9827, valid_loss :1.3017\n",
            "Epoch 1, Step 40, train_loss : 0.9044, valid_loss :1.3117\n",
            "Epoch 1, Step 50, train_loss : 0.9006, valid_loss :1.3090\n",
            "Epoch 1, Step 60, train_loss : 0.9551, valid_loss :1.2321\n",
            "Epoch 2, Step 70, train_loss : 0.6485, valid_loss :1.1660\n",
            "Epoch 2, Step 80, train_loss : 0.5493, valid_loss :1.2221\n",
            "Epoch 2, Step 90, train_loss : 0.6844, valid_loss :1.1866\n",
            "Epoch 2, Step 100, train_loss : 0.6831, valid_loss :1.0552\n",
            "Epoch 2, Step 110, train_loss : 0.6923, valid_loss :1.0763\n",
            "Epoch 2, Step 120, train_loss : 0.8114, valid_loss :1.1231\n",
            "Epoch 3, Step 130, train_loss : 0.5964, valid_loss :0.9539\n",
            "Epoch 3, Step 140, train_loss : 0.3872, valid_loss :0.9599\n",
            "Epoch 3, Step 150, train_loss : 0.4356, valid_loss :0.9948\n",
            "Epoch 3, Step 160, train_loss : 0.4016, valid_loss :0.8579\n",
            "Epoch 3, Step 170, train_loss : 0.4602, valid_loss :0.8335\n",
            "Epoch 3, Step 180, train_loss : 0.5191, valid_loss :0.8649\n",
            "Epoch 4, Step 190, train_loss : 0.5292, valid_loss :0.8214\n",
            "Epoch 4, Step 200, train_loss : 0.2374, valid_loss :0.7433\n",
            "Epoch 4, Step 210, train_loss : 0.2172, valid_loss :0.8856\n",
            "Epoch 4, Step 220, train_loss : 0.2422, valid_loss :0.7497\n",
            "Epoch 4, Step 230, train_loss : 0.2238, valid_loss :0.6988\n",
            "Epoch 4, Step 240, train_loss : 0.2612, valid_loss :0.7683\n",
            "Epoch 4, Step 250, train_loss : 0.3109, valid_loss :0.7230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGp0LRUsZGlt"
      },
      "source": [
        "#### **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZjrUIYzMlVm"
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for ((text, text_len), labels), _ in test_loader:\n",
        "        text = text.to(device)\n",
        "        text_len = text_len.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = model(text, text_len)\n",
        "\n",
        "        # test 모델 출력에서 가장 높은 값을 가지는 index를 구함\n",
        "        # 그 index가 class 번호 \n",
        "        _, max_indices = torch.max(output, 1)\n",
        "        max_indices = max_indices.data.cpu().numpy().tolist()\n",
        "\n",
        "        y_pred.extend(max_indices)\n",
        "        y_true.extend(labels.tolist())\n",
        "\n",
        "  print('Classification Report:')\n",
        "  print(classification_report(y_true, y_pred, labels=[0,1,2], digits=4))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdKeVTbXZKzx"
      },
      "source": [
        "#### **결과 예측**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYWJTRFsV7XQ",
        "outputId": "d47f36f9-06e5-4ed5-9ddc-02e8db69855d"
      },
      "source": [
        "teat = TabularDataset(path='./test.csv', format='csv',\n",
        "                      fields=fields, skip_header=True)\n",
        "\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long)\n",
        "text_field = Field(tokenize=word_tokenize, lower=True, include_lengths=True, batch_first=True)\n",
        "fields = [('text', text_field), ('labels', label_field)]\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(path=\"./\", train='train.csv', test='test.csv',\n",
        "                                  format='CSV', fields=fields, skip_header=True)\n",
        "\n",
        "train_loader = BucketIterator(train_data, batch_size=32, sort_key=lambda x: len(x.text),\n",
        "                              device=device, sort=True, sort_within_batch=True)\n",
        "\n",
        "test_loader = BucketIterator(test_data, batch_size = 32, sort_key=lambda x : len(x.text), \n",
        "                             device = device, sort = True, sort_within_batch=True)\n",
        "\n",
        "text_field.build_vocab(train_data, min_freq = 5)\n",
        "vocab_size = len(text_field.vocab) # 1016개"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dOp6DyHWoSF",
        "outputId": "50082a8c-5257-4fad-e069-d6febfb4cd7c"
      },
      "source": [
        "model_path = './model/model.pt'\n",
        "\n",
        "load_checkpoint(model_path, model, optim, device)\n",
        "\n",
        "test(model, device, test_loader)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8835    0.3776    0.5291       241\n",
            "           1     0.8139    0.9275    0.8670      1641\n",
            "           2     0.8235    0.7304    0.7742       805\n",
            "\n",
            "    accuracy                         0.8191      2687\n",
            "   macro avg     0.8403    0.6785    0.7234      2687\n",
            "weighted avg     0.8230    0.8191    0.8089      2687\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJAMtOEgW7hz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}