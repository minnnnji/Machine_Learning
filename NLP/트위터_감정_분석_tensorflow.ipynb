{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "트위터 감정 분석_tensorflow",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyDUo_3dVQOE"
      },
      "source": [
        "### 데이터 출처\n",
        "https://www.kaggle.com/vivekrathi055/sentiment-analysis-on-financial-tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eULLtP-0U1-s"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-AyOdiWsrvq"
      },
      "source": [
        "### 드라이브 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GZ92B_Rf95x",
        "outputId": "3e2ee002-6dd8-48ed-86d3-fb8ec56cd281"
      },
      "source": [
        "# valid \n",
        "!gdown --id 1EBXe8-U5OnDMNbgMRcIDygJzdTKOtEA0\n",
        "# train\n",
        "!gdown --id 1rLFoEejWhc_S2bTEHy7CoDc5jBTpbIBe"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EBXe8-U5OnDMNbgMRcIDygJzdTKOtEA0\n",
            "To: /content/valid.csv\n",
            "100% 31.5k/31.5k [00:00<00:00, 54.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rLFoEejWhc_S2bTEHy7CoDc5jBTpbIBe\n",
            "To: /content/train.csv\n",
            "100% 124k/124k [00:00<00:00, 44.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdSggfFUswD8"
      },
      "source": [
        "### 데이터 형태 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2LLOL3zvNvR"
      },
      "source": [
        "- 0 : 부정\n",
        "- 1 : 중립\n",
        "- 2 : 긍정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ltGVyI_sWhoA",
        "outputId": "2586d8d6-5503-4695-dcfc-ba5b5deb4c0d"
      },
      "source": [
        "train = pd.read_csv('train.csv', header = None)\n",
        "\n",
        "train[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>critic survey ashford hospit prime ahp amp kim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>analyst adopt bullish outlook robert half inte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zack rank strong buy semiconductor stock mlnx ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>setup like watch wed roku iq sfix shop spot ua...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>invesco ivz price target lower credit suiss group</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  critic survey ashford hospit prime ahp amp kim...  0\n",
              "1  analyst adopt bullish outlook robert half inte...  1\n",
              "2  zack rank strong buy semiconductor stock mlnx ...  2\n",
              "3  setup like watch wed roku iq sfix shop spot ua...  2\n",
              "4  invesco ivz price target lower credit suiss group  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMtilBeNszfs"
      },
      "source": [
        "### 데이터 기반 vocabulary 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2dafPM4WzT4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMOpYzbcXhGJ"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=1000,oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train.iloc[:,0])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GcjH3JbX8PQ"
      },
      "source": [
        "vocab = list(tokenizer.word_docs)[:1000]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmOqz77Xs3-w"
      },
      "source": [
        "### keras 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4yDgZWXZcJt"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding, Bidirectional, LSTM\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpXaBKOms7ZA"
      },
      "source": [
        "### 데이터 불러오기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV6pXNMLeJHZ"
      },
      "source": [
        "column_names = ['text', 'label']\n",
        "column_defaults = ['string', 'int32']\n",
        "root = './'\n",
        "train_path = root + 'train.csv'\n",
        "valid_path = root + 'valid.csv'\n",
        "\n",
        "# train data set\n",
        "train_dataset = tf.data.experimental.make_csv_dataset(train_path, column_defaults=column_defaults,\n",
        "                                                      column_names=column_names, label_name='label',\n",
        "                                                      batch_size=320, header=False, num_epochs=1)\n",
        "\n",
        "# valid data set\n",
        "valid_dataset = tf.data.experimental.make_csv_dataset(valid_path, column_defaults=column_defaults,\n",
        "                                                      column_names=column_names, label_name='label',\n",
        "                                                      batch_size=320, header=False, num_epochs=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_9Suikqsdlu"
      },
      "source": [
        "#### map 전"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa6l3vvtiulp"
      },
      "source": [
        "next(train_dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUp_1UPwshHE"
      },
      "source": [
        "#### map 후"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQxuUFjDjYHa"
      },
      "source": [
        "train_dataset = train_dataset.map(lambda text, label:(text['text'], label))\n",
        "valid_dataset = valid_dataset.map(lambda text, label:(text['text'], label))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-2LtJINi0AG"
      },
      "source": [
        "next(train_dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gslWR6m9sZZP"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNQrJmx8kNe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7b617f-911a-455f-9316-71d2dfd1a6c1"
      },
      "source": [
        "# 단어를 벡터로 바꾸는 encoder\n",
        "encoder = TextVectorization(vocabulary=vocab, output_sequence_length=200)\n",
        "\n",
        "# RNN\n",
        "# 단어 -> 인코더 -> 임베딩 => 양방향 RNN -> dence -> dence 구조\n",
        "model = Sequential([\n",
        "    encoder,\n",
        "    Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=300, mask_zero=True),\n",
        "    Bidirectional(LSTM(300)),\n",
        "    Dense(300, activation='relu'),\n",
        "    # class가 3개기 때문에 마지막 layer는 3\n",
        "    Dense(3)\n",
        "])\n",
        "\n",
        "# loss 함수 선택도 매우 중요 !\n",
        "model.compile(loss = SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer = 'Adam',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_dataset, epochs = 20, validation_data = valid_dataset, use_multiprocessing=True, workers=32)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 11s 473ms/step - loss: 0.9965 - accuracy: 0.5760 - val_loss: 0.8808 - val_accuracy: 0.6220\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.8784 - accuracy: 0.5930 - val_loss: 0.8275 - val_accuracy: 0.6840\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.7789 - accuracy: 0.6855 - val_loss: 0.6652 - val_accuracy: 0.7420\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.5997 - accuracy: 0.7695 - val_loss: 0.5823 - val_accuracy: 0.7780\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.4646 - accuracy: 0.8185 - val_loss: 0.5720 - val_accuracy: 0.7920\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.3692 - accuracy: 0.8665 - val_loss: 0.5268 - val_accuracy: 0.8120\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.2766 - accuracy: 0.8995 - val_loss: 0.5739 - val_accuracy: 0.8180\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.2222 - accuracy: 0.9205 - val_loss: 0.6044 - val_accuracy: 0.8180\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.1842 - accuracy: 0.9345 - val_loss: 0.6697 - val_accuracy: 0.7680\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.1582 - accuracy: 0.9455 - val_loss: 0.8774 - val_accuracy: 0.8220\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.1308 - accuracy: 0.9590 - val_loss: 0.7165 - val_accuracy: 0.8200\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0994 - accuracy: 0.9695 - val_loss: 0.8574 - val_accuracy: 0.8160\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0938 - accuracy: 0.9725 - val_loss: 0.8467 - val_accuracy: 0.8340\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0843 - accuracy: 0.9735 - val_loss: 0.8132 - val_accuracy: 0.8360\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0640 - accuracy: 0.9820 - val_loss: 0.8375 - val_accuracy: 0.8380\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0631 - accuracy: 0.9810 - val_loss: 0.8807 - val_accuracy: 0.8420\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 0.9488 - val_accuracy: 0.8300\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0500 - accuracy: 0.9830 - val_loss: 1.1008 - val_accuracy: 0.8140\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 1.0376 - val_accuracy: 0.8240\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 1.1117 - val_accuracy: 0.8140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmRPq0hetmLG"
      },
      "source": [
        "### test 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHZ-B-r6tkH7",
        "outputId": "467e50b0-9406-4017-9314-987fff954348"
      },
      "source": [
        "!gdown --id 1ugaRfNbetYH2dxrS8cB5KR07s1kCBPG1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ugaRfNbetYH2dxrS8cB5KR07s1kCBPG1\n",
            "To: /content/test.csv\n",
            "\r  0% 0.00/168k [00:00<?, ?B/s]\r100% 168k/168k [00:00<00:00, 51.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUKin4c7trFZ"
      },
      "source": [
        "test_path = root + 'test.csv'\n",
        "\n",
        "test_dataset = tf.data.experimental.make_csv_dataset(test_path, column_defaults=column_defaults,\n",
        "                                                     column_names = column_names, header=False,\n",
        "                                                     num_epochs = 1, batch_size = 32, label_name = 'label')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX4LtJMIuNQX"
      },
      "source": [
        "test_dataset = test_dataset.map(lambda text, label:(text['text'], label))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV_Ae-4CuV7U",
        "outputId": "bcf8dfaf-e3d9-480d-fe73-0336036c1a50"
      },
      "source": [
        "loss, acc = model.evaluate(test_dataset)\n",
        "print('test loss : {}\\ntest acc : {}'.format(loss, acc))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84/84 [==============================] - 1s 9ms/step - loss: 1.1488 - accuracy: 0.7906\n",
            "test loss : 1.1487869024276733\n",
            "test acc : 0.7905505895614624\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}